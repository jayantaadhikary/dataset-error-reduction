{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1b43db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import pandas as pd\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1c9466",
   "metadata": {},
   "source": [
    "## SQuAD V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e3777be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242d38c1ec704566b2f600a496935faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1a0e15eb78452d873608db64632981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a95bf2e4234e92845fd3f69e16688d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb99b5a05c964c62929bae7b466745f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed0ac907478b40c89f75362f3efbc69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15237652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a1302f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset['train']).sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06196170",
   "metadata": {},
   "outputs": [],
   "source": [
    "validationDf = pd.DataFrame(dataset['validation']).sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "71a8b819",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.chat(model=\"mistral\", messages=[{\n",
    "    'role': 'user',\n",
    "    'content': 'I am performing extractive question answering. I will provide you a context, question and answer. You need to provide me if the answer is correct or wrong. Just write \"Correct\" or \"Wrong\"'\n",
    "}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8928d89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Understood. I will judge whether the provided answer is correct or wrong based on the given context and question.\\n\\nContext: Apple Inc. is an American multinational technology company headquartered in Cupertino, California, that designs, develops, and sells consumer electronics, computer software, and online services. Its hardware products include the iPhone smartphone, the iPad tablet computer, the Mac personal computer, the iPod portable media player, the Apple Watch smartwatch, the AirPods wireless earbuds, and the Apple TV digital media player.\\n\\nQuestion: Which company manufactures the iPad?\\nAnswer: Microsoft Corporation.\\n\\nVerdict: Wrong.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "981f7aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.chat(model=\"mistral\", messages=[{\n",
    "    'role': 'user',\n",
    "    'content': 'Just provide me \"Correct\" or \"Wrong\". Don\\'t provide anything else'\n",
    "}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12ec6187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I. The capital city of France is:\\n\\nA) London\\nB) Madrid\\nC) Berlin\\nD) Paris\\n\\nAnswer: D. Paris.\\n\\nII. The largest planet in our solar system is:\\n\\nA) Mars\\nB) Jupiter\\nC) Venus\\nD) Saturn\\n\\nAnswer: B. Jupiter.\\n\\nIII. The currency of Japan is:\\n\\nA) Euro\\nB) Pound\\nC) Yen\\nD) Dollar\\n\\nAnswer: C. Yen.\\n\\nIV. The tallest mountain in the world is:\\n\\nA) Everest\\nB) Kilimanjaro\\nC) K2\\nD) Mauna Loa\\n\\nAnswer: A. Mount Everest.\\n\\nV. The largest country by land area is:\\n\\nA) Russia\\nB) Canada\\nC) United States\\nD) China\\n\\nAnswer: A. Russia.\\n\\nVI. The human body contains approximately:\\n\\nA) 78 organs\\nB) 100 trillion cells\\nC) 5 liters of blood\\nD) 206 bones\\n\\nAnswer: B. 100 trillion cells.\\n\\nVII. The deepest part of the ocean is:\\n\\nA) Mariana Trench\\nB) Red Sea\\nC) Pacific Ocean\\nD) Indian Ocean\\n\\nAnswer: A. Mariana Trench.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50ee653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.chat(model=\"mistral\", messages=[{\n",
    "    'role': 'user',\n",
    "    'content': 'Why all the answers you are providing are having an explaination.Just provide me \"Correct\" or \"Wrong\". Don\\'t provide anything else'\n",
    "}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0ef3343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I apologize for any previous responses that included explanations when you only requested a \"Correct\" or \"Wrong.\" I will make sure to keep my answers brief going forward. However, please note that providing a simple \"Correct\" or \"Wrong\" may not always be sufficient, as it depends on the context and complexity of the question. If you have a specific factual query, feel free to ask and I\\'ll do my best to give you a succinct answer.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b498b31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModelFeedback(row, model):\n",
    "    context = row[\"context\"]\n",
    "    question = row[\"question\"]\n",
    "    answer = row[\"answers\"]\n",
    "    \n",
    "    prompt = f\"I am providing you the context, question and answer. Please tell me if it is correct or not.Just provide 'correct' or 'wrong'. Do not provide any explaination or anything else.\\nContext: {context}\\nQuestion: {question}\\nAnswer: {answer}\"\n",
    "    \n",
    "    response = ollama.chat(model=model, messages=[{\n",
    "        'role': 'user',\n",
    "        'content': prompt,\n",
    "    }])\n",
    "    \n",
    "    return response['message']['content']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4de4dbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Mistral Verdict\"] = df.apply(getModelFeedback, model=\"mistral\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01171e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>Mistral Verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>56cfad77234ae51400d9be5e</td>\n",
       "      <td>New_York_City</td>\n",
       "      <td>More than 200 newspapers and 350 consumer maga...</td>\n",
       "      <td>Which New York-based newspaper has won the Pul...</td>\n",
       "      <td>{'text': ['The New York Times'], 'answer_start...</td>\n",
       "      <td>correct. However, it's important to note that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43587</th>\n",
       "      <td>5726bea0708984140094d01e</td>\n",
       "      <td>Mexico_City</td>\n",
       "      <td>The Centro Nacional de las Artes (National Cen...</td>\n",
       "      <td>What is the name of the CCU center opened in 2...</td>\n",
       "      <td>{'text': ['Tlatelolco'], 'answer_start': [622]}</td>\n",
       "      <td>correct.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39573</th>\n",
       "      <td>572802ae4b864d1900164215</td>\n",
       "      <td>Northwestern_University</td>\n",
       "      <td>Many students are involved in community servic...</td>\n",
       "      <td>What is the name of the university's group ser...</td>\n",
       "      <td>{'text': ['Global Engagement Summer Institute'...</td>\n",
       "      <td>correct.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74522</th>\n",
       "      <td>572ee21dc246551400ce476e</td>\n",
       "      <td>Transistor</td>\n",
       "      <td>The essential usefulness of a transistor comes...</td>\n",
       "      <td>What is an additional use of the transistor?</td>\n",
       "      <td>{'text': ['turn current on or off in a circuit...</td>\n",
       "      <td>correct.\\n\\nThe context explains that a trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45773</th>\n",
       "      <td>5726e0c55951b619008f8123</td>\n",
       "      <td>Predation</td>\n",
       "      <td>Mimicry is a related phenomenon where an organ...</td>\n",
       "      <td>What is the phenomenon where an organism looks...</td>\n",
       "      <td>{'text': ['Mimicry'], 'answer_start': [0]}</td>\n",
       "      <td>correct.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74564</th>\n",
       "      <td>572f9165a23a5019007fc774</td>\n",
       "      <td>Transistor</td>\n",
       "      <td>FETs are further divided into depletion-mode a...</td>\n",
       "      <td>What channel corresponds with high current?</td>\n",
       "      <td>{'text': ['n-channel devices'], 'answer_start'...</td>\n",
       "      <td>Correct. The context states that a more posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46013</th>\n",
       "      <td>57266a9bf1498d1400e8df16</td>\n",
       "      <td>British_Empire</td>\n",
       "      <td>At the concluding Treaty of Utrecht, Philip re...</td>\n",
       "      <td>Which country did Britain acquire Gibraltar an...</td>\n",
       "      <td>{'text': ['Spain'], 'answer_start': [252]}</td>\n",
       "      <td>correct.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25317</th>\n",
       "      <td>5706e5579e06ca38007e91fe</td>\n",
       "      <td>Atlantic_City,_New_Jersey</td>\n",
       "      <td>Marvin Gardens, the leading yellow property on...</td>\n",
       "      <td>In what year did Parker Brothers acknowledge a...</td>\n",
       "      <td>{'text': ['1995'], 'answer_start': [326]}</td>\n",
       "      <td>correct.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21641</th>\n",
       "      <td>56f970b39e9bad19000a091c</td>\n",
       "      <td>List_of_numbered_streets_in_Manhattan</td>\n",
       "      <td>181st Street is a major thoroughfare running t...</td>\n",
       "      <td>Which river does 181st Street run near?</td>\n",
       "      <td>{'text': ['Hudson River'], 'answer_start': [221]}</td>\n",
       "      <td>correct.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>56ccf12b62d2951400fa64f4</td>\n",
       "      <td>Sino-Tibetan_relations_during_the_Ming_dynasty</td>\n",
       "      <td>The Columbia Encyclopedia distinguishes betwee...</td>\n",
       "      <td>What did Thomas Laird dismiss the Yuan dynasty...</td>\n",
       "      <td>{'text': ['a non-Chinese polity'], 'answer_sta...</td>\n",
       "      <td>correct.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id  \\\n",
       "4306   56cfad77234ae51400d9be5e   \n",
       "43587  5726bea0708984140094d01e   \n",
       "39573  572802ae4b864d1900164215   \n",
       "74522  572ee21dc246551400ce476e   \n",
       "45773  5726e0c55951b619008f8123   \n",
       "74564  572f9165a23a5019007fc774   \n",
       "46013  57266a9bf1498d1400e8df16   \n",
       "25317  5706e5579e06ca38007e91fe   \n",
       "21641  56f970b39e9bad19000a091c   \n",
       "2256   56ccf12b62d2951400fa64f4   \n",
       "\n",
       "                                                title  \\\n",
       "4306                                    New_York_City   \n",
       "43587                                     Mexico_City   \n",
       "39573                         Northwestern_University   \n",
       "74522                                      Transistor   \n",
       "45773                                       Predation   \n",
       "74564                                      Transistor   \n",
       "46013                                  British_Empire   \n",
       "25317                       Atlantic_City,_New_Jersey   \n",
       "21641           List_of_numbered_streets_in_Manhattan   \n",
       "2256   Sino-Tibetan_relations_during_the_Ming_dynasty   \n",
       "\n",
       "                                                 context  \\\n",
       "4306   More than 200 newspapers and 350 consumer maga...   \n",
       "43587  The Centro Nacional de las Artes (National Cen...   \n",
       "39573  Many students are involved in community servic...   \n",
       "74522  The essential usefulness of a transistor comes...   \n",
       "45773  Mimicry is a related phenomenon where an organ...   \n",
       "74564  FETs are further divided into depletion-mode a...   \n",
       "46013  At the concluding Treaty of Utrecht, Philip re...   \n",
       "25317  Marvin Gardens, the leading yellow property on...   \n",
       "21641  181st Street is a major thoroughfare running t...   \n",
       "2256   The Columbia Encyclopedia distinguishes betwee...   \n",
       "\n",
       "                                                question  \\\n",
       "4306   Which New York-based newspaper has won the Pul...   \n",
       "43587  What is the name of the CCU center opened in 2...   \n",
       "39573  What is the name of the university's group ser...   \n",
       "74522       What is an additional use of the transistor?   \n",
       "45773  What is the phenomenon where an organism looks...   \n",
       "74564        What channel corresponds with high current?   \n",
       "46013  Which country did Britain acquire Gibraltar an...   \n",
       "25317  In what year did Parker Brothers acknowledge a...   \n",
       "21641            Which river does 181st Street run near?   \n",
       "2256   What did Thomas Laird dismiss the Yuan dynasty...   \n",
       "\n",
       "                                                 answers  \\\n",
       "4306   {'text': ['The New York Times'], 'answer_start...   \n",
       "43587    {'text': ['Tlatelolco'], 'answer_start': [622]}   \n",
       "39573  {'text': ['Global Engagement Summer Institute'...   \n",
       "74522  {'text': ['turn current on or off in a circuit...   \n",
       "45773         {'text': ['Mimicry'], 'answer_start': [0]}   \n",
       "74564  {'text': ['n-channel devices'], 'answer_start'...   \n",
       "46013         {'text': ['Spain'], 'answer_start': [252]}   \n",
       "25317          {'text': ['1995'], 'answer_start': [326]}   \n",
       "21641  {'text': ['Hudson River'], 'answer_start': [221]}   \n",
       "2256   {'text': ['a non-Chinese polity'], 'answer_sta...   \n",
       "\n",
       "                                         Mistral Verdict  \n",
       "4306    correct. However, it's important to note that...  \n",
       "43587                                           correct.  \n",
       "39573                                           correct.  \n",
       "74522   correct.\\n\\nThe context explains that a trans...  \n",
       "45773                                           correct.  \n",
       "74564   Correct. The context states that a more posit...  \n",
       "46013                                           correct.  \n",
       "25317                                           correct.  \n",
       "21641                                           correct.  \n",
       "2256                                            correct.  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61184fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "validationDf[\"Mistral Verdict\"] = validationDf.apply(getModelFeedback, model=\"mistral\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93c004f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>Mistral Verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>56d9ca0adc89441400fdb821</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>There would be no more scoring in the third qu...</td>\n",
       "      <td>What yard line was the Broncos on when Manning...</td>\n",
       "      <td>{'text': ['50-yard line.', '41', '50'], 'answe...</td>\n",
       "      <td>wrong. The context states that Ealy recovered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5859</th>\n",
       "      <td>5727403af1498d1400e8f527</td>\n",
       "      <td>American_Broadcasting_Company</td>\n",
       "      <td>At the same time he made attempts to help grow...</td>\n",
       "      <td>What Western was a flagship program for ABC ar...</td>\n",
       "      <td>{'text': ['The Lone Ranger', 'The Lone Ranger'...</td>\n",
       "      <td>correct.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8575</th>\n",
       "      <td>57292994af94a219006aa131</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>In the motor rallying arena, Kenya is home to ...</td>\n",
       "      <td>What is Kenya the home of?</td>\n",
       "      <td>{'text': ['the world famous Safari Rally', 'Sa...</td>\n",
       "      <td>correct.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5450</th>\n",
       "      <td>57269d68708984140094cbd8</td>\n",
       "      <td>Victoria_and_Albert_Museum</td>\n",
       "      <td>The interiors of the three refreshment rooms w...</td>\n",
       "      <td>Who designed the ceiling and stained-glass win...</td>\n",
       "      <td>{'text': ['Edward Burne-Jones', 'Edward Burne-...</td>\n",
       "      <td>Correct.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6958</th>\n",
       "      <td>57274e975951b619008f87fa</td>\n",
       "      <td>Construction</td>\n",
       "      <td>Several project structures can assist the owne...</td>\n",
       "      <td>These project structures allow the owner to in...</td>\n",
       "      <td>{'text': ['architects, interior designers, eng...</td>\n",
       "      <td>correct.\\n\\nThe context mentions \"architects,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6882</th>\n",
       "      <td>5728ed94ff5b5019007da97f</td>\n",
       "      <td>Civil_disobedience</td>\n",
       "      <td>Howard Zinn writes, \"There may be many times w...</td>\n",
       "      <td>Why should one not go to jail?</td>\n",
       "      <td>{'text': ['accept jail penitently', 'is to swi...</td>\n",
       "      <td>Wrong. The context states that one should not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>57094d489928a8140047150d</td>\n",
       "      <td>Sky_(United_Kingdom)</td>\n",
       "      <td>BSkyB utilises the VideoGuard pay-TV scramblin...</td>\n",
       "      <td>Who has design authority over all of the digit...</td>\n",
       "      <td>{'text': ['BSkyB', 'BSkyB', 'BSkyB'], 'answer_...</td>\n",
       "      <td>correct.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9388</th>\n",
       "      <td>573007fab2c2fd140056876f</td>\n",
       "      <td>Rhine</td>\n",
       "      <td>From the death of Augustus in AD 14 until afte...</td>\n",
       "      <td>Which direction did Romans use to drift throug...</td>\n",
       "      <td>{'text': ['eastwards', 'eastwards', 'eastwards...</td>\n",
       "      <td>correct.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8353</th>\n",
       "      <td>5728dab94b864d1900164f98</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Kenya (/ˈkɛnjə/; locally [ˈkɛɲa] ( listen)), o...</td>\n",
       "      <td>What is the capitol of Kenya?</td>\n",
       "      <td>{'text': ['Nairobi', 'Nairobi', 'Nairobi'], 'a...</td>\n",
       "      <td>Correct.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8380</th>\n",
       "      <td>5728fa576aef051400154922</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Fossils found in Kenya suggest that primates r...</td>\n",
       "      <td>Who helped discover the Turkana Boy?</td>\n",
       "      <td>{'text': ['Richard Leakey', 'Kamoya Kimeu', 'K...</td>\n",
       "      <td>correct. (The answer provided in the text is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id                          title  \\\n",
       "763   56d9ca0adc89441400fdb821                  Super_Bowl_50   \n",
       "5859  5727403af1498d1400e8f527  American_Broadcasting_Company   \n",
       "8575  57292994af94a219006aa131                          Kenya   \n",
       "5450  57269d68708984140094cbd8     Victoria_and_Albert_Museum   \n",
       "6958  57274e975951b619008f87fa                   Construction   \n",
       "...                        ...                            ...   \n",
       "6882  5728ed94ff5b5019007da97f             Civil_disobedience   \n",
       "2826  57094d489928a8140047150d           Sky_(United_Kingdom)   \n",
       "9388  573007fab2c2fd140056876f                          Rhine   \n",
       "8353  5728dab94b864d1900164f98                          Kenya   \n",
       "8380  5728fa576aef051400154922                          Kenya   \n",
       "\n",
       "                                                context  \\\n",
       "763   There would be no more scoring in the third qu...   \n",
       "5859  At the same time he made attempts to help grow...   \n",
       "8575  In the motor rallying arena, Kenya is home to ...   \n",
       "5450  The interiors of the three refreshment rooms w...   \n",
       "6958  Several project structures can assist the owne...   \n",
       "...                                                 ...   \n",
       "6882  Howard Zinn writes, \"There may be many times w...   \n",
       "2826  BSkyB utilises the VideoGuard pay-TV scramblin...   \n",
       "9388  From the death of Augustus in AD 14 until afte...   \n",
       "8353  Kenya (/ˈkɛnjə/; locally [ˈkɛɲa] ( listen)), o...   \n",
       "8380  Fossils found in Kenya suggest that primates r...   \n",
       "\n",
       "                                               question  \\\n",
       "763   What yard line was the Broncos on when Manning...   \n",
       "5859  What Western was a flagship program for ABC ar...   \n",
       "8575                         What is Kenya the home of?   \n",
       "5450  Who designed the ceiling and stained-glass win...   \n",
       "6958  These project structures allow the owner to in...   \n",
       "...                                                 ...   \n",
       "6882                     Why should one not go to jail?   \n",
       "2826  Who has design authority over all of the digit...   \n",
       "9388  Which direction did Romans use to drift throug...   \n",
       "8353                      What is the capitol of Kenya?   \n",
       "8380               Who helped discover the Turkana Boy?   \n",
       "\n",
       "                                                answers  \\\n",
       "763   {'text': ['50-yard line.', '41', '50'], 'answe...   \n",
       "5859  {'text': ['The Lone Ranger', 'The Lone Ranger'...   \n",
       "8575  {'text': ['the world famous Safari Rally', 'Sa...   \n",
       "5450  {'text': ['Edward Burne-Jones', 'Edward Burne-...   \n",
       "6958  {'text': ['architects, interior designers, eng...   \n",
       "...                                                 ...   \n",
       "6882  {'text': ['accept jail penitently', 'is to swi...   \n",
       "2826  {'text': ['BSkyB', 'BSkyB', 'BSkyB'], 'answer_...   \n",
       "9388  {'text': ['eastwards', 'eastwards', 'eastwards...   \n",
       "8353  {'text': ['Nairobi', 'Nairobi', 'Nairobi'], 'a...   \n",
       "8380  {'text': ['Richard Leakey', 'Kamoya Kimeu', 'K...   \n",
       "\n",
       "                                        Mistral Verdict  \n",
       "763    wrong. The context states that Ealy recovered...  \n",
       "5859                                           correct.  \n",
       "8575                                           correct.  \n",
       "5450                                           Correct.  \n",
       "6958   correct.\\n\\nThe context mentions \"architects,...  \n",
       "...                                                 ...  \n",
       "6882   Wrong. The context states that one should not...  \n",
       "2826                                           correct.  \n",
       "9388                                           correct.  \n",
       "8353                                           Correct.  \n",
       "8380   correct. (The answer provided in the text is ...  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validationDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "591ccbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "validationDf.to_csv(\"squad_correct_wrong_prompt_mistral.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f856919",
   "metadata": {},
   "source": [
    "## SQUAD V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a8851f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4cb0f36405444a913ae363a63a55fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/8.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc68ea16a4a4eaa8ee14190540f9318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/16.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e16fd535c1b54c9ba317f02ab792a2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.35M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc83cce163ee41deb22e46a67136b444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/130319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab65d3141c84d2e8b71df4e0bbe70be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/11873 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "squadV2 = load_dataset(\"rajpurkar/squad_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8957557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "v2Validation = pd.DataFrame(squadV2['validation']).sample(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3e7c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "v2Validation[\"mistral Verdict\"] = v2Validation.apply(getModelFeedback, model=\"mistral\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed6dfe6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>mistral Verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3205</th>\n",
       "      <td>5ad14966645df0001a2d1583</td>\n",
       "      <td>European_Union_law</td>\n",
       "      <td>None of the original treaties establishing the...</td>\n",
       "      <td>What other entity was not established at the s...</td>\n",
       "      <td>{'text': [], 'answer_start': []}</td>\n",
       "      <td>wrong. The European Court of Human Rights was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9073</th>\n",
       "      <td>5ad268a9d7d075001a429281</td>\n",
       "      <td>Rhine</td>\n",
       "      <td>The mouth of the Rhine into Lake Constance for...</td>\n",
       "      <td>What is one of the mammal animals that lives i...</td>\n",
       "      <td>{'text': [], 'answer_start': []}</td>\n",
       "      <td>Wrong. The question asks for a mammal animal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10074</th>\n",
       "      <td>5acfebe477cf76001a6864d8</td>\n",
       "      <td>Islamism</td>\n",
       "      <td>These attacks resonated with conservative Musl...</td>\n",
       "      <td>What did Saudi Arabia not try to repress to co...</td>\n",
       "      <td>{'text': [], 'answer_start': []}</td>\n",
       "      <td>Wrong. The question asks about what Saudi Ara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9154</th>\n",
       "      <td>572f64ccb2c2fd14005680bb</td>\n",
       "      <td>Rhine</td>\n",
       "      <td>The Upper Rhine region was changed significant...</td>\n",
       "      <td>What is the Bassin de compensation de Plobshei...</td>\n",
       "      <td>{'text': ['large compensation pools', 'large c...</td>\n",
       "      <td>correct.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>5ad3f7ac604f3c001a3ffa3d</td>\n",
       "      <td>Normans</td>\n",
       "      <td>One of the claimants of the English throne opp...</td>\n",
       "      <td>Who did the Scotish king take hostage?</td>\n",
       "      <td>{'text': [], 'answer_start': []}</td>\n",
       "      <td>Wrong. The Scottish king took the Scottish pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265</th>\n",
       "      <td>5711669550c2381900b54adf</td>\n",
       "      <td>Steam_engine</td>\n",
       "      <td>The Rankine cycle is sometimes referred to as ...</td>\n",
       "      <td>What is the Rankine cycle sometimes called?</td>\n",
       "      <td>{'text': ['practical Carnot cycle', 'practical...</td>\n",
       "      <td>correct.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>5ad26aa8d7d075001a429324</td>\n",
       "      <td>Rhine</td>\n",
       "      <td>A regulation of the Rhine was called for, with...</td>\n",
       "      <td>What lake no longer has any silt?</td>\n",
       "      <td>{'text': [], 'answer_start': []}</td>\n",
       "      <td>Wrong. The context states that it is expected...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3360</th>\n",
       "      <td>5726c5a9f1498d1400e8eac8</td>\n",
       "      <td>European_Union_law</td>\n",
       "      <td>In regard to companies, the Court of Justice h...</td>\n",
       "      <td>In which case did the Court of Justice hold th...</td>\n",
       "      <td>{'text': ['Überseering BV v Nordic Constructio...</td>\n",
       "      <td>Correct.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8543</th>\n",
       "      <td>57293e983f37b3190047818b</td>\n",
       "      <td>Intergovernmental_Panel_on_Climate_Change</td>\n",
       "      <td>In 2001, 16 national science academies issued ...</td>\n",
       "      <td>When was the joint statement on climate change...</td>\n",
       "      <td>{'text': ['2001', '2001', '2001'], 'answer_sta...</td>\n",
       "      <td>Correct.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6185</th>\n",
       "      <td>5a67b759f038b7001ab0c43b</td>\n",
       "      <td>Private_school</td>\n",
       "      <td>In the final years of the apartheid era, paren...</td>\n",
       "      <td>What was abolished during the apartheid era?</td>\n",
       "      <td>{'text': [], 'answer_start': []}</td>\n",
       "      <td>Wrong. The legal form of \"Model C\" schools wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id                                      title  \\\n",
       "3205   5ad14966645df0001a2d1583                         European_Union_law   \n",
       "9073   5ad268a9d7d075001a429281                                      Rhine   \n",
       "10074  5acfebe477cf76001a6864d8                                   Islamism   \n",
       "9154   572f64ccb2c2fd14005680bb                                      Rhine   \n",
       "119    5ad3f7ac604f3c001a3ffa3d                                    Normans   \n",
       "...                         ...                                        ...   \n",
       "2265   5711669550c2381900b54adf                               Steam_engine   \n",
       "9089   5ad26aa8d7d075001a429324                                      Rhine   \n",
       "3360   5726c5a9f1498d1400e8eac8                         European_Union_law   \n",
       "8543   57293e983f37b3190047818b  Intergovernmental_Panel_on_Climate_Change   \n",
       "6185   5a67b759f038b7001ab0c43b                             Private_school   \n",
       "\n",
       "                                                 context  \\\n",
       "3205   None of the original treaties establishing the...   \n",
       "9073   The mouth of the Rhine into Lake Constance for...   \n",
       "10074  These attacks resonated with conservative Musl...   \n",
       "9154   The Upper Rhine region was changed significant...   \n",
       "119    One of the claimants of the English throne opp...   \n",
       "...                                                  ...   \n",
       "2265   The Rankine cycle is sometimes referred to as ...   \n",
       "9089   A regulation of the Rhine was called for, with...   \n",
       "3360   In regard to companies, the Court of Justice h...   \n",
       "8543   In 2001, 16 national science academies issued ...   \n",
       "6185   In the final years of the apartheid era, paren...   \n",
       "\n",
       "                                                question  \\\n",
       "3205   What other entity was not established at the s...   \n",
       "9073   What is one of the mammal animals that lives i...   \n",
       "10074  What did Saudi Arabia not try to repress to co...   \n",
       "9154   What is the Bassin de compensation de Plobshei...   \n",
       "119               Who did the Scotish king take hostage?   \n",
       "...                                                  ...   \n",
       "2265         What is the Rankine cycle sometimes called?   \n",
       "9089                   What lake no longer has any silt?   \n",
       "3360   In which case did the Court of Justice hold th...   \n",
       "8543   When was the joint statement on climate change...   \n",
       "6185        What was abolished during the apartheid era?   \n",
       "\n",
       "                                                 answers  \\\n",
       "3205                    {'text': [], 'answer_start': []}   \n",
       "9073                    {'text': [], 'answer_start': []}   \n",
       "10074                   {'text': [], 'answer_start': []}   \n",
       "9154   {'text': ['large compensation pools', 'large c...   \n",
       "119                     {'text': [], 'answer_start': []}   \n",
       "...                                                  ...   \n",
       "2265   {'text': ['practical Carnot cycle', 'practical...   \n",
       "9089                    {'text': [], 'answer_start': []}   \n",
       "3360   {'text': ['Überseering BV v Nordic Constructio...   \n",
       "8543   {'text': ['2001', '2001', '2001'], 'answer_sta...   \n",
       "6185                    {'text': [], 'answer_start': []}   \n",
       "\n",
       "                                         mistral Verdict  \n",
       "3205    wrong. The European Court of Human Rights was...  \n",
       "9073    Wrong. The question asks for a mammal animal ...  \n",
       "10074   Wrong. The question asks about what Saudi Ara...  \n",
       "9154                                            correct.  \n",
       "119     Wrong. The Scottish king took the Scottish pr...  \n",
       "...                                                  ...  \n",
       "2265                                            correct.  \n",
       "9089    Wrong. The context states that it is expected...  \n",
       "3360                                            Correct.  \n",
       "8543                                            Correct.  \n",
       "6185    Wrong. The legal form of \"Model C\" schools wa...  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca6b216",
   "metadata": {},
   "source": [
    "## AdversarialQA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c97f9ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6249199d29b46449c72853cad6c570e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.35M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "435e0a8e28374b02b81b9e65c4a99f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/495k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016b7c3ee7dc40c993e541bdf4e99817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/457k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805ca692df1f4f2fbff97bc65b21ef75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/30000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745b5e802cff4ff1890dfe05ba38e982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda9b142b61047f99b401c9cb6d7e8b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adversarialData = load_dataset(\"UCLNLP/adversarial_qa\", \"adversarialQA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b3b8e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers', 'metadata'],\n",
       "        num_rows: 30000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers', 'metadata'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers', 'metadata'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversarialData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e7830015",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarialValidation = adversarialData[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9e1cc670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'ba0946490bf8d1228e12756d6ecc7d9895f6a693',\n",
       " 'title': 'Newcastle_upon_Tyne',\n",
       " 'context': 'Following guidelines set in the National Cycling strategy, Newcastle first developed its cycling strategy in 1998. As of 2012, the local council social aims and objectives for cycling include: highlighting the usage of cycling to cut city congestion; educating that cycling promotes healthy living… The authority also has infrastructure aims and objectives which include: developing on road cycle networks on quieter streets; making safer routes on busier streets; innovating and implementing contraflows on one way streets; developing the existing off road cycle route networks and improve signage; joining up routes that are partially or completely isolated; Increase the number of cycle parking facilities; working with employers to integrate cycling into workplace travel plans; link the local networks to national networks.',\n",
       " 'question': 'What has been added to streets to allow traffic in both directions?',\n",
       " 'answers': {'text': ['contraflows on one way streets'],\n",
       "  'answer_start': [493]},\n",
       " 'metadata': {'split': 'validation', 'model_in_the_loop': 'Combined'}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversarialValidation[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c2941f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' correct.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getModelFeedback(adversarialValidation[20], model='mistral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90119aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
